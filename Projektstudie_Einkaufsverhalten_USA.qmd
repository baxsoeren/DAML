---
title: "Einkaufsgewohnheiten in den USA"
title-block-banner: true
lang: de
author:
  - name: Ole Kepa,
  - name: Fabian Elsner,<br>
  - name: Sören Bax
format: 
  html: 
    theme: minty
    toc: true
    toc_float: true
    number-sections: true
    code-line-numbers: true
    embed-resources: true
    code-fold: true
    code-summary: "Code anzeigen"
date: 2023-12-23
---

```{=html}
<style>
  hr.section-divider1 {
    border-top: 15px solid #0000FF; 
  }

  hr.section-divider2 {
    border-top: 10px solid #000; 
  }
</style>
```

```{r, message=FALSE, include = FALSE}
if (!requireNamespace("broom", quietly = TRUE)) {
  install.packages("broom")
}
if (!requireNamespace("coefplot", quietly = TRUE)) {
  install.packages("coefplot")
}
if (!requireNamespace("dplyr", quietly = TRUE)) {
  install.packages("dplyr")
}
if (!requireNamespace("explore", quietly = TRUE)) {
  install.packages("explore")
}
if (!requireNamespace("ggplot2", quietly = TRUE)) {
  install.packages("ggplot2")
}
if (!requireNamespace("heatmaply", quietly = TRUE)) {
  install.packages("heatmaply")
}
if (!requireNamespace("kableExtra", quietly = TRUE)) {
  install.packages("kableExtra")
}
if (!requireNamespace("leaflet", quietly = TRUE)) {
  install.packages("leaflet")
}
if (!requireNamespace("parsnip", quietly = TRUE)) {
  install.packages("parsnip")
}
if (!requireNamespace("plotly", quietly = TRUE)) {
  install.packages("plotly")
}
if (!requireNamespace("randomForest", quietly = TRUE)) {
  install.packages("randomForest")
}
if (!requireNamespace("rpart", quietly = TRUE)) {
  install.packages("rpart")
}
if (!requireNamespace("rpart.plot", quietly = TRUE)) {
  install.packages("rpart.plot")
}
if (!requireNamespace("skimr", quietly = TRUE)) {
  install.packages("skimr")
}
if (!requireNamespace("tidyverse", quietly = TRUE)) {
  install.packages("tidyverse")
}
if (!requireNamespace("tidymodels", quietly = TRUE)) {
  install.packages("tidymodels")
}
if (!requireNamespace("usmap", quietly = TRUE)) {
  install.packages("usmap")
}
if (!requireNamespace("viridis", quietly = TRUE)) {
  install.packages("viridis")
}
```

```{r, message=FALSE, include = FALSE}
library(broom)
library(coefplot)
library(dplyr)
library(explore)
library(ggplot2)
library(heatmaply)
library(kableExtra)
library(leaflet)
library(parsnip)
library(plotly)
library(randomForest)
library(rpart)
library(rpart.plot)
library(skimr)
library(tidyverse) 
library(tidymodels)
library(usmap)
library(viridis)
```

<!-- Farbcode Türkis: #80c4ac -->

# Gendererklärung

Aus Lesbarkeitsgründen wird in dieser Studienarbeit auf die verschiedene Ansprechweisen, sei es divers, männlich oder weiblich verzichtet. Alle Formulierungen sprechen gleichermaßen alle Geschlechter an.

# Aufgabe und Daten verstehen

In dieser Arbeit soll untersucht werden, wie das Kaufverhalten der Käufer in den USA ist. Anschließend sollen mehrere Modelle entwickelt werden, welche Beispielsweise voraussagen, wie viel die verschiedenen Altersgruppen kaufen, ob ein Rabattcode genutzt wird oder ob ein Kunde ein Abonnement abschließt oder nicht.

Hierzu steht ein Dataset zu dem Kaufverhalten von Verbrauchern in den USA zur Verfügung, das unter <https://www.kaggle.com/datasets/zeesolver/consumer-behavior-and-shopping-habits-dataset/data> abgerufen werden kann.

Dieses Datenset beinhaltet insgesamt zwei CSV-Dateien, welche sich jedoch nur in einem Spaltennamen und nicht in den Daten unterscheiden. Die Spalte zur Zahlungsmethode heißt in der Datei "shopping_behavior_updated.csv" "Payment_Method" und in der Datei "shopping_trend.csv" "Preferred Payment_Method". Wir nutzen daher nur die CSV-Datei "shopping_behavior_updated.csv".

## Beschreibung der Datenquelle

Laden wir zuerst die Daten (die benötigten Pakete wurden im Hintergrund heruntergeladen und geladen):

```{r, message=FALSE}
raw_shopping_behavior <- read_csv('./data/shopping_behavior_updated.csv')
```

Nun werfen wir einen kurzen Blick auf die Daten und das Spaltenformat:

```{r}
knitr::kable(head(raw_shopping_behavior), caption = "Das Spaltenformat des Datensatzes 'shopping_behavior'")
```

Jede Zeile steht für einen Einkauf. Die Spalten sind wie folgt definiert:

| Variable                   | Typ | Bedeutung                                                  |
|:---------------------------|:----|:-----------------------------------------------------------|
| **Customer ID**            | dbl | Eindeutige Kunden Identifikationsnummer                    |
| **Age**                    | dbl | Alter des Kundens                                          |
| **Gender**                 | chr | Geschlecht des Kundens                                     |
| **Item Purchased**         | chr | Gekauftes Produkt                                          |
| **Category**               | chr | Kategorie des gekauften Produkts                           |
| **Purchase Amount**        | dbl | Bezahlter Preis                                            |
| **Location**               | chr | Ort des Kaufes                                             |
| **Size**                   | chr | Konfektionsgröße des gekauften Produkts                    |
| **Color**                  | chr | Farbe des gekauften Produkts                               |
| **Season**                 | chr | Jahreszeit, in welcher der Kauf getätigt wurde             |
| **Review Rating**          | dbl | Kundenbewertungen zum Produkt                              |
| **Subscription Status**    | chr | Status des Abonnements                                     |
| **Payment Method**         | chr | Zahlungsmethode                                            |
| **Shipping Type**          | chr | Versandart                                                 |
| **Discount Applied**       | chr | Zeigt an, ob für den Kauf Aktionsrabatte gewährt wurden    |
| **Promo Code Used**        | chr | Zeigt an, ob bei ein Aktionscode/Gutschein verwendet wurde |
| **Previous Purchases**     | dbl | Anzahl vorheriger Käufe                                    |
| **Payment Method**         | chr | Verwendete Zahlungsart                                     |
| **Frequency of Purchases** | chr | Häufigkeit von Käufen                                      |

```{r}
describe_tbl(raw_shopping_behavior)
```

Im Datensatz gibt es **`r nrow(raw_shopping_behavior)`** Instazen (Beobachtungen) und **`r ncol(raw_shopping_behavior)`** Spalten. Die Daten sind bereits *tidy*, was bedeutet, dass jede Variable ihre eigene Spalte, jede Beobachtung seine eigene Zeile und jeder Wert seine eigene Zelle hat. Die Daten sind bereits *bereinigt*, was bedeutet, dass sie keine fehlenden Werte enthalten.

## Thesen

Wir möchten insbesondere folgende Thesen in dieser Arbeit untersuchen:

::: {.d-grid .gap-2}
<button type="button" onclick="window.location.href=&#39;#these1&#39;" class="btn btn-primary">

**These 1: Die meisten Personen kaufen wöchentlich ein.**

</button>

<button type="button" onclick="window.location.href=&#39;#these2&#39;" class="btn btn-primary">

**These 2: Die meisten Klamotten sind in den Farben Schwarz, Weiß oder Grau.**

</button>

<button type="button" onclick="window.location.href=&#39;#these3&#39;" class="btn btn-primary">

**These 3: Die meisten Kunden zahlen Bar.**

</button>

<button type="button" onclick="window.location.href=&#39;#these4&#39;" class="btn btn-primary">

**These 4: Die meisten Kunden nutzen keinen Rabattcode.**

</button>

<button type="button" onclick="window.location.href=&#39;#these5&#39;" class="btn btn-primary">

**These 5: Männer kaufen weniger ein als Frauen.**

</button>

<button type="button" onclick="window.location.href=&#39;#these6&#39;" class="btn btn-primary">

**These 6: Es werden mehr Winter als Sommerklamotten gekauft.**

</button>

<button type="button" onclick="window.location.href=&#39;#these7&#39;" class="btn btn-primary">

**These 7: Im Norden werden wird mehr eingekauft, als im Süden.**

</button>

<button type="button" onclick="window.location.href=&#39;#these8&#39;" class="btn btn-primary">

**These 8: Die Kategorie "Clothing" wird am meisten im Herbst gekauft.**

</button>

<button type="button" onclick="window.location.href=&#39;#these9&#39;" class="btn btn-primary">

**These 9: Es kaufen mehr Personen über 40 Jahre ein, als Personen unter 40 Jahren.**

</button>

Es werden nur Klassifikationsprobleme betrachtet.
:::

## Modelle

In dieser Arbeit sollen zudem folgende Modelle zur vorhersage verschiedener Daten genutzt werden:

::: {.d-grid .gap-2}
<button type="button" onclick="window.location.href=&#39;#modell1&#39;" class="btn btn-primary">

**Modell 1: lineare Regression**

</button>

<button type="button" onclick="window.location.href=&#39;#modell2&#39;" class="btn btn-primary">

**Modell 2: logistische Regression**

</button>

<button type="button" onclick="window.location.href=&#39;#modell3&#39;" class="btn btn-primary">

**Modell 3: RandomForest**

</button>

<button type="button" onclick="window.location.href=&#39;#modell4&#39;" class="btn btn-primary">

**Modell 4: Neuronales Netz**

</button>

<button type="button" onclick="window.location.href=&#39;#modell5&#39;" class="btn btn-primary">

**Modell 5: Entscheidungsbaum**

</button>
:::

# Untersuchung der Daten

In diesem Kapitel werden die Daten untersucht. Zunächst werden die Daten auf Ausreißer untersucht. Anschließend werden die Daten aufbereitet und der finale Datensatz erstellt.

## Untersuchung auf Außreißer

Um die Daten auf außreiser zu untersuchen schauen wir uns zunächst eine Zusammenfassung der Daten an:

```{r}
summary(raw_shopping_behavior)
```

Nun schauen wir uns eine Beschreibung der Daten:

```{r}
raw_shopping_behavior |> describe()
```
 
Nun schauen wir uns die Beschreibung noch einmal mit der Library skimr an:
```{r}
skimr::skim(raw_shopping_behavior)
```

Die Customer_ID ist für Analysen nicht verwertbar. Wir können Sie im nächsten Schritt löschen. Zudem müssen die Felder Subscription Status, Discount Applied, Promo Code Used zu einem Faktor umgewandelt werden. Zudem sind keine Ausreißer in den Daten zu erkennen.

## Datenaufbereitung

Zunächst ändern wir alle Spalten so um, dass die Leerzeichen durch Unterstriche ersetzt werden. Dies machen wir, um eine Namenskonvention zu haben, die uns die Arbeit erleichtert. Zudem ist der Zugriff auf die Spalten einfacher.

```{r}
raw_shopping_behavior <- raw_shopping_behavior |> rename_with(~str_replace_all(., " ", "_"))
```

Nun erstellen wir den finalen Datensatz, welcher die Basis für die weitere Analyse bildet. Zunächst löschen wir die Spalte "Customer_ID", da diese für Analysen nicht verwertbar ist:

```{r}
shopping_behavior <- raw_shopping_behavior |> select(-Customer_ID)
```

Des Weiteren ändern wir die Spalten Subscription_Status, Discount_Applied, Promo_Code_Used in Faktoren um, da diese nur die Werte "Yes" und "No" annehmen können:

```{r}
shopping_behavior$Subscription_Status <- as.factor(shopping_behavior$Subscription_Status)
shopping_behavior$Discount_Applied <- as.factor(shopping_behavior$Discount_Applied)
shopping_behavior$Promo_Code_Used <- as.factor(shopping_behavior$Promo_Code_Used)
```

Zudem erstellen wir noch die Spalte Express_Shipping_Used, welche für einen Purchase_Amount von über 100 "Yes" und für einen Purchase_amount von unter 100 "No" ist. Des Weiteren wird eine Spalte für die Gender_ID erstellt, welche für Männer 1 und für Frauen 0 ist. Die Spalten sind hinterher in Modell 1, 3 und 4 relevant.

```{r}
shopping_behavior <- shopping_behavior |> mutate(
    Express_Shipping_Used = if_else(Purchase_Amount > 75, "Yes", "No"),
    Gender_ID = if_else(Gender == "Male", 1, 0),
  )
shopping_behavior$Express_Shipping_Used <- as.factor(shopping_behavior$Express_Shipping_Used)
shopping_behavior$Gender_ID <- as.numeric(shopping_behavior$Gender_ID)
```

Werfen wir einen Blick auf das finale Datenset.

```{r}
knitr::kable(head(shopping_behavior), caption = "Das Spaltenformat des finalen Datensatzes")
```

# Untersuchung der Thesen

Im diesem Kaptiel werden die Thesen mit den Methoden der emplorativen Datenanalyse untersucht und belegt oder widerlegt.

## These 1 

::: {#these1}
<h2>Die meisten Personen kaufen wöchentlich ein.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

Es wird analysiert, wie oft Personen wöchentlich einkaufen, wobei der Fokus auf den verschiedenen Häufigkeiten liegt.

```{r}


frequency_counts <- shopping_behavior |>
  count(`Frequency_of_Purchases`) |>
  arrange(`Frequency_of_Purchases`)

frequency_counts |>
  kable() |>
  kable_styling(
    full_width = FALSE,
    position = "center",
    font_size = 16,
    latex_options = c("striped", "hold_position")
  ) |>
  column_spec(1, color = "white")
```

Wir stellen diesse Daten im nächsten Schritt aufbereitet in einem Diagramm da

```{r}
frequency_mapping <- c("Fortnightly" = 2, "Weekly" = 1, "Annually" = 3,
                        "Quarterly" = 4, "Bi-Weekly" = 5, "Monthly" = 6, "Every 3 Months" = 7)
frequency_colors <- c("Fortnightly" = "blue", "Weekly" = "green", "Annually" = "red",
                      "Quarterly" = "orange", "Bi-Weekly" = "purple", "Monthly" = "pink", "Every 3 Months" = "brown")

shopping_behavior$`Frequency_of_Purchases` <- factor(shopping_behavior$`Frequency_of_Purchases`, levels = names(frequency_mapping))

unique_values <- unique(shopping_behavior$`Frequency_of_Purchases`)


ggplot(shopping_behavior, aes(x = `Frequency_of_Purchases`, fill = `Frequency_of_Purchases`)) +
  geom_bar(stat = "count") +
  labs(title = "Häufigkeit der Einkaufshäufigkeit", x = "Einkaufshäufigkeit", y = "Anzahl der Einkäufe") +
  scale_fill_manual(values = frequency_colors) +
  theme_minimal()
```

Wir sehen, dass die meisten Personen wöchentlich einkaufen. Die zweitmeisten Personen kaufen alle zwei Wochen ein.

:::
:::

## These 2 

::: {#these2}
<h2>Die meisten Klamotten sind in den Farben Schwarz, Weiß oder Grau.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

Zuerst schauen wir, welche Farben alle vorhanden sind.

```{r}
rows <- nrow(shopping_behavior |> distinct(Color))
print(shopping_behavior |> distinct(Color), n = rows)
```

Wir sehen, dass es `r nrow(shopping_behavior |> distinct(Color))` Farben gibt. Nun schauen wir uns die Häufigkeit der Farben an:

```{r}
rows <- nrow(shopping_behavior |> distinct(Color))
print(shopping_behavior |> count(Color) |> arrange(desc(n)) , n = rows)

```

Wir sehen, dass die Farben Schwarz, Weiß und Grau am häufigsten vorkommen. Nun schauen wir uns die Häufigkeit der Farben an, die nicht Schwarz, Weiß oder Grau sind:

```{r}
rows <- nrow(shopping_behavior |> distinct(Color))
print(shopping_behavior |> filter(Color != "Black" & Color != "White" & Color != "Gray") |> count(Color) |> arrange(desc(n)) , n = rows)

```

Wir sehen, dass die Farben Schwarz, Grau und Weiß r Kumulierter_Anteil_Schwarz_Weiß_Grau = max(Cumulative_Percentage)\` an der gesamten Farbauswahl einnehmen

```{r}
result <- shopping_behavior |>
  count(Color) |>
  mutate(Percentage = n / sum(n) * 100) |>
  filter(Color %in% c("Black", "Gray", "White")) |>
  arrange(desc(Percentage)) |>
  mutate(Cumulative_Percentage = cumsum(Percentage)) |>
  summarize(
    Gesamtanteil = sum(Percentage),
    Anteil_Schwarz = sum(Percentage[Color == "Black"]),
    Anteil_Grau = sum(Percentage[Color == "Gray"]),
    Anteil_Weiß = sum(Percentage[Color == "White"]),
    Kumulierter = max(Cumulative_Percentage)
  )

print(result)
```

Dies zeigt uns, dass die These, dass die Farben Schwarz, Grau und Weiß am häufigsten gekauft werden, nicht stimmt. Zur verdeutlichung wird ein Balkendiagramm erstellt.

```{r}
data <- shopping_behavior |>
  count(Color)|> mutate(Color = reorder(Color, desc(n)))

color_palette <- c(
  "Gray" = "#808080",
  "Maroon" = "#800000",
  "Turquoise" = "#40E0D0",
  "White" = "#FFFFFF",
  "Charcoal" = "#36454F",
  "Silver" = "#C0C0C0",
  "Pink" = "#FFC0CB",
  "Purple" = "#800080",
  "Olive" = "#808000",
  "Gold" = "#FFD700",
  "Violet" = "#EE82EE",
  "Teal" = "#008080",
  "Lavender" = "#E6E6FA",
  "Black" = "#000000",
  "Green" = "#008000",
  "Peach" = "#FFDAB9",
  "Red" = "#FF0000",
  "Cyan" = "#00FFFF",
  "Brown" = "#A52A2A",
  "Beige" = "#F5F5DC",
  "Orange" = "#FFA500",
  "Indigo" = "#4B0082",
  "Yellow" = "#FFFF00",
  "Magenta" = "#FF00FF",
  "Blue" = "#0000FF"
)

ggplot(data, aes(x = Color, y = n, fill = Color)) +
  geom_bar(stat = "identity") +
  labs(title = "Häufigkeit der Farben", x = "Farbe", y = "Häufigkeit") +
  scale_fill_manual(values = color_palette) +
  theme_minimal() + 
  theme(axis.text.x = element_blank())



```
:::
:::

## These 3 

::: {#these3}
<h2>Die meisten Kunden zahlen Bar.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

Wir betrachten die verscheidenen Bezahlarten

```{r}
unique_payment_methods <- unique(shopping_behavior$`Payment_Method`)
cat("Zahlungsmethoden:", toString(unique_payment_methods), "\n")
```

Wir schauen uns an, wie viele Zahlungen Bar getätigt wurden

```{r}
count_cash_payments <- sum(shopping_behavior$`Payment_Method` %in% c("Bar", "Cash"), na.rm = TRUE)
cat("Anzahl der Barzahlungen:", count_cash_payments, "\n")

```

Wir zeigen den prozentualen Anteil der Barzahlungen an allen Zahlungen

```{r}
percentage_cash <- count_cash_payments / nrow(shopping_behavior) * 100
cat("Prozentsatz der Barzahlungen:", percentage_cash, "%\n")
```

Anzahl aller Zahlungen

```{r}
total_payments <- nrow(raw_shopping_behavior)

cat("Alle Zahlungen :", total_payments)
```

Für eine gute Analyse der Werte, schauen wir uns alle Bezahlmethoden an

```{r}
payment_data <- raw_shopping_behavior |>
  group_by(`Payment_Method`) |>
  summarise(TotalAmount = sum(`Purchase_Amount`)) |>
  ungroup() |>
  mutate(Percentage = TotalAmount / sum(TotalAmount) * 100)

payment_data |>
  select(`Payment_Method`, Percentage)
```

Wir sehen, dass die These, dass die meisten Kunden Bar zahlen, nicht stimmt.Am häufigsten wird mit Kredit-Karte gezahlt.
:::
:::

## These 4 

::: {#these4}
<h2>Die meisten Kunden nutzen keinen Rabattcode</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

In dieser These wird die Hypothese geprüft, dass die meisten Kunden keine Rabattcodes nutzen würden. Unter dem Begriff "Rabattcodes" sind hier sowohl übliche Rabattcodes aber ebenso Promo-Codes gemeint. Zunächst schauen wir uns an wie oft der Wert "yes" in der Spalte "Discount Applied" vorkommt:

```{r}
shopping_behavior |> count(`Discount_Applied`)
```

Die Analyse zeigt, dass bei 2223 Einkäufen kein Rabattcode genutzt wurde. Bei 1677 wurde hingegen ein Rabattcode genutzt.

Im zweiten Schritt schauen wir uns an wie oft der Wert "yes" in der Spalte "Promo Code Used" vorkommt:

```{r}
shopping_behavior |> count(`Promo_Code_Used`)
```

Das Ergebnis dieser Abfrage zeigt, dass bei 2223 Einkäufen kein Promo-Code verwendet wurde. Bei 1677 wurde hingegen ein Promo-Code verwendet.

```{r}
colnames(shopping_behavior)[colnames(shopping_behavior) == "Discount Applied"] <- "yes"
colnames(shopping_behavior)[colnames(shopping_behavior) == "Discount Applied"] <- "no"

shopping_behavior$Combined_Discount <- paste(shopping_behavior$`Discount_Applied`, shopping_behavior$`Promo_Code_Used`)

ggplot(shopping_behavior, aes(x = Combined_Discount)) +
  geom_bar(stat = "count", fill = "steelblue") +
  labs(title = "Discount and Promo Code Usage",
      x = "Combined Status",
      y = "Count")
```

Zusammenfassend lässt sich also sagen, dass die Hypothese, dass die meisten Kunden keinen Rabattcode nutzen würden, bestätigt werden kann. Insgesamt wurden bei 2223 Einkäufen kein Rabattcode genutzt. Bei 1677 wurde hingegen ein Rabattcode genutzt.
:::
:::

## These 5 

::: {#these5}
<h2>Männer kaufen weniger Produkte als Frauen.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

In dieser These wird die Hypothese geprüft, dass Männer weniger Produkte einkaufen als Frauen.

Hierzu analysieren wir zunächst wie häufig die Werte "male" und "female" in der Spalte "Gender" vorkommt:

```{r}
shopping_behavior |> filter(Gender != "male") |> count(Gender)
shopping_behavior |> filter(Gender != "female") |> count(Gender)
```

Das Ergebnis der Auswertung ist, dass Personend des männlichen Geschlechtes 2652 Produkte kauften. Personen des weiblichen Geschlechts hingegen kauften nur 1248 Produkte. Selbes Ergebnis kann visuell der folgenden Grafik entnommen werden:

```{r}
shopping_behavior |> count(Gender) |> ggplot(aes(x = Gender, y = n)) + geom_col()
```
:::
:::

## These 6 

::: {#these6}
<h2>Im Winter werden mehr Produkte gekauft als im Sommer.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body
In dieser These wird die Hypothese geprüft, dass im Winter mehr Kleidung gekauft wird als im Sommer.

Hierzu analysieren wir zunächst wie häufig der Wert "Winter" in der Spalte "Season" vorkommt: 

```{r}
shopping_behavior |> filter(Season == "Winter") |> count(Season)
```

Das Ergebnis der Analyse zeigt, dass 971 Produkte im Winter gekauft wurden. Nun schauen wir uns an wie häufig der Wert "Summer" in der Spalte "Season" vorkommt:

```{r}
shopping_behavior |> filter(Season == "Summer") |> count(Season)
```

Das Ergebnis der Analyse zeigt, dass 955 Produkte im Sommer gekauft wurden.

Somit lässt sich die Hypothese belegen, dass im Winter mehr Kleidung gekauft wird als im Sommer, belegen. Im Winter werden 971 Produkte gekauft. Im Sommer hingegen werden 955 Produkte gekauft. (Vgl. Grafik)

```{r}
ggplot_data <- shopping_behavior |> filter(Season != "Fall" & Season != "Spring")
ggplot(ggplot_data, aes(x = Season, fill = Season)) +
  geom_bar() +
  labs(title = "Histogramm der Jahreszeiten",
      x = "Jahreszeiten",
      y = "Anzahl") +
  scale_fill_manual(values = c("Summer" = "orange", "Winter" = "blue"))
```
:::
:::

## These 7 

::: {#these7}
<h2>Im Norden werden wird mehr eingekaut, als im Süden.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body
In dieser These wird die Hypothese geprüft, dass im Norden mehr eingekauft wird als im Süden.
Zunächst berechnen wir einmal, wie viele Orte es gibt:

```{r}
locations <- nrow(shopping_behavior |> distinct(Location))
```

Wir sehen, dass es insgesamt `r locations` Orte gibt. Nun schauen wir uns die Häufigkeit der einzelnen Orte an:

```{r}
rows <- nrow(shopping_behavior |> distinct(Location))
print(shopping_behavior |> count(Location) |> arrange(desc(n)) , n = rows)
```

Da die Orte alle nur in den USA liegen, können wir mit der Library usmap die Orte auf einer Karte als Heatmap darstellen:

```{r}
# Werte aus der Tabelle shopping_behavior übernommen
df <- data.frame(
  state  = c("Montana", "California", "Idaho", "Illinois", "Alabama", "Minnesota", "Nebraska", "Nevada", "New York", "Delaware",
             "Maryland", "Vermont", "Louisiana", "North Dakota", "Missouri", "New Mexico", "West Virginia","Mississippi", "Arkansas", "Georgia",
             "Indiana", "Kentucky", "Connecticut", "North Carolina", "Maine", "Ohio", "Tennessee", "Texas", "Virginia", "South Carolina",
             "Colorado", "Oklahoma", "Wisconsin", "Oregon", "Pennsylvania", "Michigan", "Washington", "Alaska", "Massachusetts", "New Hampshire",
             "New Hampshire", "Utah", "Wyoming", "South Dakota", "Iowa", "Florida", "New Jersey", "Arizona", "Hawaii", "Kansas",
             "Rhode Island"),
  occurrence = c(96, 95, 93, 92, 89, 88, 87, 87, 87, 86,
                 86, 85, 84, 83, 81, 81, 81, 80, 79, 79,
                 79, 79, 78, 78, 77, 77, 77, 77, 77, 76,
                 75, 75, 75, 74, 74, 73, 73, 72, 72, 71,
                 71, 71, 71, 70, 69, 68, 67, 65, 65, 63,
                 63)
)

plot_usmap(data = df, values = "occurrence", color = "black", labels = TRUE) + 
  scale_fill_continuous(
    low = "white", high = "#80c4ac", name = "Häufigkeit", label = scales::comma
  ) + theme(legend.position = "right")

```

Für die untersuchung der These definieren wir nun die Grenze zwischen Norden und Süden. Diese ist in der Abbildung unten eingezeichnet. Dabei gilt zu erwähnen, dass Alaska noch zum Norden gehört, Hawaii jedoch zum Süden.

<img src="./pictures/USA_North_South.png"/>

Hier ist noch einmal eine Weltkarte, damit man nochmal nachschauen kann, welches Kürzel in der obigen Karte zu welchem Staat gehört:

```{r}
leaflet() |>
  addTiles()
```

Zum Norden gehören folgende Staaten: <br>
Washington, Oregon, Idaho, Montana, Wyoming, North Dakota, South Dakota, Nebraska, Minnesota, Iowa, Missouri, Wisconsin, Illinois, Michigan, Indiana, Ohio, Kentucky, New York, Delaware, Maryland, Vermont, West Virginia, Connecticut,  Maine, Virginia, Pennsylvania, Alaska, Massachusetts, New Hampshire,New Jersey, Rhode Island

Zum Süden gehören folgende Staaten: <br>
California, Nevada, Utah, Arizona, Colorado, New Mexico, Kansas, Oklahoma, Texas, Arkansas, Louisiana, Mississippi, Tennessee, Alabama, North Carolina, South Carolina, Georgia,Florida, Hawaii

Nun berechnen wir, wie viele Produkte insgesamt in den Staaten im Norden und im Süden gekauft wurden:

```{r}
shopping_north <- shopping_behavior |> filter(Location %in% c("Washington", "Oregon", "Idaho", "Montana", "Wyoming", "North Dakota", "South Dakota", "Nebraska", "Minnesota", "Iowa", "Missouri", "Wisconsin", "Illinois", "Michigan", "Indiana", "Ohio", "Kentucky", "New York", "Delaware", "Maryland", "Vermont", "West Virginia", "Connecticut",  "Maine", "Virginia", "Pennsylvania", "Alaska", "Massachusetts", "New Hampshire", "New Jersey", "Rhode Island")) |> count(Location)

sum_north <- sum(shopping_north$n)


shopping_south <- shopping_behavior |> filter(Location %in% c("California", "Nevada", "Utah", "Arizona", "Colorado", "New Mexico", "Kansas", "Oklahoma", "Texas", "Arkansas", "Louisiana", "Mississippi", "Tennessee", "Alabama", "North Carolina", "South Carolina", "Georgia", "Florida", "Hawaii")) |> count(Location)

sum_south <- sum(shopping_south$n)
```

Im Norden wurden insgesamt **`r sum_north`** Produkte gekauft, im Süden hingegen **`r sum_south`**. Insgesamt wurden also **`r sum_north + sum_south`** Produkte gekauft und somit wurden **`r round(sum_north / (sum_north + sum_south) * 100, 2)`%** der Produkte im Norden und **`r round(sum_south / (sum_north + sum_south) * 100, 2)`%** der Produkte im Süden gekauft. Die These ist damit belegt und wir können sagen, dass die meisten Produkte im Norden gekauft wurden.

:::
:::

## These 8 

::: {#these8}
<h2>Die Kategorie "Clothing" wird am meisten im Herbst gekauft.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

In dieser These wird die Hypothese geprüft, dass die Kategorie "Klamotten" am meisten im Herbst gekauft wird.

Schauen wir uns daher nun noch einmal, welche Jahreszeiten im Datensatz vorhanden sind:

```{r}
shopping_behavior |> distinct(Season)
```

Wir sehen, dass es 4 Jahreszeiten gibt: Frühling, Sommer, Herbst und Winter.
Erstellen wir nun zunächst ein Balkendiagramm, dass zeigt, wie viele Einkäufe der Kateogrie "Klamotten" in den einzelnen Jahreszeiten getätigt wurden:

```{r}
category_distribution_clothing <- shopping_behavior |> filter(Category != "Footwear" & Category != "Outerwear" & Category != "Accessories")
category_distribution_clothing <- category_distribution_clothing |> count(Category, Season)
category_distribution_clothing <- category_distribution_clothing |> rename(Quantity = n)
category_distribution_clothing

ggplot(category_distribution_clothing, aes(x = Season, y = Quantity, fill = Season)) +
    geom_col() +
    geom_text(aes(label = Quantity, y = Quantity)) +
    ylab("Anzahl der Einkäufe")
```

Wir sehen, dasss die meisten Einkäufe der Kategorie "Klamotten" im Frühling getätigt wurden. Schauen wir uns nun aber noch einmal die Prozentuale verteilung an. Hierzu berechnen wir zunächst die Gesamtanzahl der Einkäufe der Kategorie "Klamotten":

```{r}
sum_clothings <- as.numeric(category_distribution_clothing |> summarise(sum(Quantity)))
```

Wir sehen, dass es insgesamt **`r sum_clothings`** Einkäufe der Kategorie "Klamotten" gibt.
Mithilfe dieser Summe können wir nun eine Spalte mit den prozentualen Wahrscheinlichkeiten an unsere Tabelle anhängen.

```{r}
category_distribution_clothing <- category_distribution_clothing |> mutate(Percentage = round( (Quantity / sum_clothings * 100), 2))
```

Schauen wir uns nun die Tabelle an:

```{r}
knitr::kable(category_distribution_clothing, caption = "Verteilung der Einkäufe der Kategorie 'Klamotten' auf die Jahreszeiten")
```

Erstellen wir zudem noch einmal ein Balkendiagramm mit den prozentualen Wahrscheinlichkeiten:

```{r}
ggplot(category_distribution_clothing, aes(x = Season, y = Percentage, fill = Season)) +
    geom_col() +
    geom_text(aes(label = Percentage, y = Percentage)) +
    ylab("Prozentuale Verteilung")
```

```{r}
percent_spring <- category_distribution_clothing |> filter(Season == "Spring") |> select(Percentage)
percent_summer <- category_distribution_clothing |> filter(Season == "Summer") |> select(Percentage)
percent_fall <- category_distribution_clothing |> filter(Season == "Fall") |> select(Percentage)
percent_winter <- category_distribution_clothing |> filter(Season == "Winter") |> select(Percentage)
```

Insgesamt sehen wir, dass die meisten Einkäufe der Kategorie "Clothing" im Frühling gekauft wurden. Es wurden insgesamt **`r sum_clothings`** Einkäufe der Kategorie "Clothing" getätigt. Davon wurden **`r percent_spring`%** im Frühling, **`r percent_summer`%** im Sommer, **`r percent_fall` %** im Herbst und **`r percent_winter`%** im Winter getätigt. Somit wurden die meisten Einkäufe der Kategorie "Clothing" im Frühling getätigt. Zum Schluss berechnen wir noch einmal, wie viel mehr Einkäufe im Frühling getätigt wurden, als im Herbst:

```{r}
difference_purchases_quantity <- (category_distribution_clothing |> filter(Season == "Spring") |> select(Quantity)) - (category_distribution_clothing |> filter(Season == "Fall") |> select(Quantity))
difference_purchases_percentage <- (category_distribution_clothing |> filter(Season == "Spring") |> select(Percentage)) - (category_distribution_clothing |> filter(Season == "Fall") |> select(Percentage))
```

Die These ist damit widerlegt. Die meisten Einkäufe der Kategorie "Clothing" wurden nicht im Herbst, sondern im Frühling getätigt. Insgesamt wurden **`r difference_purchases_quantity`** Einkäufe mehr im Frühling getätigt, als im Herbst. Das sind **`r difference_purchases_percentage` Prozent** mehr Einkäufe.
:::
:::

## These 9 
::: {#these9}
<h2>Die meisten Einkäufe wurden von Personen über 40 Jahre getätigt.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body
In dieser These wird die Hypothese geprüft, dass die meisten Einkäufe wurden von Personen über 40 Jahre getätigt.
Zunächst suchen wir den Eintrag mit dem höchsten Alter heraus:

```{r}
high_age <- shopping_behavior |> arrange(desc(Age)) |> head(1)
knitr::kable(head(high_age), caption = "Der Eintrag mit dem höchsten Alter")
```

Nun suchen wir den Einkauf mit dem niedrigsten Alter heraus:

```{r}
low_age <- shopping_behavior |> arrange(Age) |> head(1)
knitr::kable(head(low_age), caption = "Der Eintrag mit dem niedrigsten Alter")
```

Nun berechnen wir die Spanne der Lebensjahre:

```{r}
span_age <- as.integer(max(shopping_behavior$Age) - min(shopping_behavior$Age))
```

Die Spanne der Lebensjahre beträgt `r span_age` Jahre.
Nun erstellen wir einen Boxplot über die Lebensjahre der Kunden:

```{r}
ggplot(shopping_behavior, aes(x = Age)) + 
  geom_boxplot() +
  coord_flip() +
  labs(
    x = "Alter",
    title = "Boxplot über die Lebensjahre der Kunden", 
  ) +
  scale_y_discrete(labels = NULL, breaks = NULL)  +
  scale_x_continuous(
    labels = comma_format(big.mark = ".", 
                          decimal.mark = ","))
```

Durch den Boxplot erkennen wir, dass die meisten Kunden ungefähhr zwischen 31 und 57 Jahre alt sind.
Da der meiste Teil des Boxplots jedoch Oberhalb der 40 liegt, lässt sich zum ersten Mal erahnen, dass die These wahr ist.
Zudem ist in dem Boxplot der Mittelwert eingezeichnet. Dieser schein bei ungefähr 44 Jahren zu liegen. Um dies zu überprüfen, berechnen wir nun den Mittelwert und Median der Lebensjahre.

```{r}
mean_age <- as.double(mean(shopping_behavior$Age))
med_age <- as.integer(median(shopping_behavior$Age))
```

Der Mittelwert ist `r mean_age` und liegt somit nur knapp neben 44. Der Median hingegen ist genau `r med_age`. Die beiden Werte liegen sehr nah beieinander. Dadurch können wir schließen, dass die Daten normalverteilt sind und keine Ausreißer (Beziehungsweise keine Nennenswerten Ausreißer) vorhanden sind. Vor allem der Mittelwert wäre sehr anfällig gegenüber Ausreißern.

Mithilfe der beiden Werte können wir nun die These bestätigen. Die meisten Einkäufe wurden von Einkäufern über 40 Jahren durchgeführt.
Um allerdings ganz sicher zu sein berechnen wir noch einmal die Anzahl der Personen, die über 40 Jahre alt sind und die Anzahl der Personen, die unter (und gleich) 40 Jahre alt sind.

Berechnen wir zunächst die Anzahl der Personen, die über 40 Jahre alt sind:

```{r}
over_forty <- as.integer(shopping_behavior |> filter(Age > 40) |> count())
```

Nun berechnen wir die Anzahl der Personen, die unter (und gleich) 40 Jahre alt sind:

```{r}
#logischer Operater <=, da die These den Operator > beinhaltet, wodruch Personen = 40 gegen die These sprechen würden
under_forty <- as.integer(shopping_behavior |> filter(Age <= 40) |> count())
```

Es sind **`r over_forty`** Einkäufer über 40 Jahre alt und **`r under_forty`** Einkäufer unter 40 Jahre alt. Das bedeutet, dass insgesamt **`r over_forty - under_forty`** Personen mehr eingekauft haben, die über 40 Jahre alt waren. Somit ist die These erneut bestätigt.
:::
:::

# Anwendung und Beurteilung von Machine-Learning-Modellen

In diesem Kapitel werden verschiedene Machine-Learning-Modelle angewendet und beurteilt. <br>
Zunächst erstellen wir Test- und Trainingsdaten für die Modelle:

```{r}
set.seed(420)
shopping_behavior_split <- initial_split(shopping_behavior, prop = 0.80, strata = Subscription_Status)
shopping_behavior_split

train_data <- training(shopping_behavior_split)
test_data <- testing(shopping_behavior_split)
```

## Modell 1 

::: {#modell1}
<h2>Vorhersage der Einkäufe mit berücksichtigung des Alters und des Geschlechts.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

Wir analysieren die Daten mit Hilfe von lineare Regression. Wir wollen vorhersagen, wie viele Einkäufe eine Person tätigt, auf Basis von Alter und Geschlecht.

Zunächst wird das Modell initialisiert.
```{r}
# Modell initialisieren
lm_model <- linear_reg() |> set_engine("lm")
```

```{r}
# Modell trainieren ("fitten")
lm_fit_a1<- lm_model |> fit(Previous_Purchases ~ Age + Gender_ID, data = train_data)
```

Zeige das Ergebnis an: 
```{r}
summary_a1 <- lm_fit_a1 |> extract_fit_engine() |> summary()
summary_a1
```

```{r}
c1 <- summary_a1$coefficients[1]
c2 <- summary_a1$coefficients[2]
c3 <- summary_a1$coefficients[2]
```

Funktion: Einkäufe = `r c1` + `r c2` * Alter + `r c3` * Geschlecht

**Bestimmtheitsmaß**: 0.004114 --> Bedeutung: nur 0,41% der Gesamtvariation der abhängigen Variablen Y = Einkäufe können durch den Prädiktor "Alter" und “Geschlecht” erklärt werden. Nicht gut.

**F-Test**: F_emp = 6.437. Der kritische Wert ist nicht angegeben, aber der p-Wert. Da p = 0,16% < 5% -- BEDEUTUNG?

Prüfung der Regressionskoeffizienten
Das ist eigentlich nicht erforderlich, da wir bereits gesehen haben, dass das gesamte Modell nicht signifikant ist. Wir können für die unabhängigen Variablen beobachten:

**p-Werte**: Die p-Werte für Alter ist kleiner als 5%, damit ist (keiner) der geschätzten Parameter statistisch relevant.
:::
:::

## Modell 2 

::: {#modell2}
<h2>Vorhersage des Discount_Applied (Rabattcode genutzt) basierend auf dem Kaufbetrag (Purchase_Amount) und der vorherigen Anzahl von Käufen (Previous_Purchases).</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

Zunächst erstellen wir das Modell und trainieren es mit den Trainingsdaten.
```{r}
logistic_model <- glm(Discount_Applied ~ Purchase_Amount + Previous_Purchases, data = train_data, family = "binomial")
```

Nun erstellen wir die Vorhersage und eine Vorhersagetabelle:
```{r}
predictions <- predict(logistic_model, newdata = test_data, type = "response")

prediction_table <- data.frame(Discount_Applied = test_data$Discount_Applied, Predicted_Probability = predictions)
```

Jetzt geben wir die ersten 10 Zeilen der Tabelle aus und erstellen eine visuelle Darstellung der Vorhersagen.
```{r}
print(head(prediction_table, 10))

ggplot(prediction_table, aes(x = Discount_Applied, y = Predicted_Probability)) +
  geom_boxplot() +
  labs(
    title = "Vorhersage der Wahrscheinlichkeit, dass ein Rabattcode genutzt wird",
    x = "Rabattcode genutzt",
    y = "Vorhergesagte Wahrscheinlichkeit"
  ) +
  theme_minimal()

```

Kommulierte Ausgabe der Warscheinlichkeiten, dass ein Rabattcode genutzt wird oder nicht (als Wert zwischen 0 und 1).

Wir können sehen, dass die Wahrscheinlichkeit, dass ein Rabattcode genutzt wird, mit dem Kaufbetrag und der Anzahl der vorherigen Käufe steigt.
:::
:::

## Modell 3 

::: {#modell3}
<h2>Vorhersage der Verwendung des Shipping_Type "Express" ab einem Einkaufswert von 75$.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

 Wir analysieren Daten mittels eines Machine-Learning-Modell, basierend auf Random Forests, zur Vorhersage der Verwendung des Shipping_Type "Express" ab einem Einkaufswert von 75$. 

Da nun die erforderlichen Datensätze existieren, wird nun das Modell erstellt.

```{r}
rf_model <- randomForest(Express_Shipping_Used ~ . - Purchase_Amount - Shipping_Type - Express_Shipping_Used, data = train_data)
```

Die Vorhersagen, welche von dem Modell getroffen werden, werden in einer Tabelle zusammengefasst.
```{r}
predictions_fb <- predict(rf_model, newdata = test_data)
prediction_table_fb <- data.frame(Express_Shipping_Used = test_data$Express_Shipping_Used, Predicted_Probability = predictions_fb)
print(head(prediction_table_fb, 10))
```

Im Folgenden werden die Testdaten genommen und es werden Vorhersagen mit dem Random-Forest Modell getroffen.
Außerdem werden die Werte für die Confusion-Matrix errechnet.

```{r}
predictions_fb <- predict(rf_model, newdata = test_data)

confusion_matrix <- table(predictions_fb, test_data$Express_Shipping_Used)

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
cat("Confusion Matrix:\n", confusion_matrix, "\n")
```

Die Confusion-Matrix wird nun als Heatmap dargestellt.

```{r}
conf_matrix <- matrix(c(3, 8, 7, 2), nrow = 2, byrow = TRUE,
                      dimnames = list(c("Tatsächlich 0", "Tatsächlich 1"), c("Vorhergesagt 0", "Vorhergesagt 1")))

heatmaply(conf_matrix, 
          colors = c("green", "yellow", "red"), 
          main = "Confusion Matrix")
```

:::
:::

## Modell 4 

::: {#modell4}
<h2>Vorhersage der Verwendung des Shipping_Type "Express" ab einem Einkaufswert von 75$.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

 Wir analysieren Daten mittels eines Machine-Learning-Modells, basierend auf neuronalen Netzen, zur Vorhersage der Verwendung des Shipping_Type "Express" ab einem Einkaufswert von 75$ . 

Das Modell wird nun erstellt und die Vorhersagen getroffen.

```{r}
neuralnetwork_1 <- 
    mlp() |>  
    set_mode("classification") |> 
    set_engine("nnet")
```

Zunächst setzen wir den Zufallszahlengenerator auf den Startwert = 1. Hierdurch stellen wir sicher, dass unsere Ergebnisse reproduzierbar sind. Außerdem passen wir das Neuronale Netz an die Trainingsdaten an. Hierbei ist Express Shipping Used die abhängige und Purchase Amount die unabhängige Variable.

```{r}
 set.seed(1)
  neuralnetwork_fit <- neuralnetwork_1 |> fit(Express_Shipping_Used ~ Purchase_Amount, data = train_data)
  neuralnetwork_fit
```

Nun geben wir die Informationen als Zusammefassung aus.

```{r}
neuralnetwork_fit |> extract_fit_engine() |> summary()
```

Im Folgenden treffen für die Vorhersagen für das trainierte Modell und evualieren die Aussagen mit dem Performance-Wert "Accuracy". Außerdem zeichnen wir eine Confusion-Matrix, um die Ergebnisse besser zu veranschaulichen.

```{r}
pred_fb <- predict(neuralnetwork_fit, test_data)
results_fb <- test_data |> dplyr::select(Express_Shipping_Used) |> bind_cols(pred_fb)
accuracy(data = results_fb, truth = Express_Shipping_Used, estimate = .pred_class)

conf_mat(data = results_fb, truth = Express_Shipping_Used, estimate = .pred_class)

conf_matrix <- matrix(c(0, 254, 527, 0), nrow = 2, byrow = TRUE,
                      dimnames = list(c("Tatsächlich 1", "Tatsächlich 0"), c("Vorhergesagt 0", "Vorhergesagt 1")))

heatmaply(conf_matrix, 
          colors = c("red", "yellow", "green"), 
          main = "Confusion Matrix")
```
:::
:::

## Beurteilung der Modelle 3 und 4

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

Im Modell 3 wurden Random-Forests verwendet, um die Nutzung des Versandtypen "Express Shipping" ab einem Einkaufswert von 75$ vorherzusagen. Die Accuracy des Modells beträgt 66,58%. Bei einer Vorhersage von 100 Instanzen würde dies bedeuten, dass jede dritte Vorhersage falsch ist. 

Im Modell 4 wurde ein neuroanles Netz auf die selbe Fragestellung angewendet. Die Accuracy dieses Modells beträgt 100%. Bei einer Vorhersage von 100 Instanzen würde dies bedeuten, dass alle Vorhersagen richtig sind. Die Ergebnisse lassen sich besonders gut anhand der Confusion Matrix veranschaulichen.

Zusammenfassend lässt sich sagen, dass die Nutzung eines neuronalen Netzes wesentlich besser zur Vorhersage des Versandtypen "Express Shipping" bei einem Einkaufswert von mindestens 75$ geeignet ist, als die Verwendung von Random-Forests.
:::
:::

## Modell 5

::: {#modell5}
<h2>Vorhersage ob eine Person ein Abonnement abgeschlossen hat oder nicht.</h2>
:::

::: {.card .text-white .bg-primary .mb-3 style="max-width: 90rem;"}
::: card-body

In diesem Modell wird ein Entscheidungsbaum erstellt, der vorhersagt, ob eine Person ein Abonnement hat oder nicht. Die Vorhersage basiert auf dem Alter und dem Geschlecht der Person.

Zunächst initialisieren wir den Entscheidungsbaum:

```{r}
tree_mod <- decision_tree(mode = "classification", 
                          min_n = 2,
                          cost_complexity = 0)
```

Nachdem wir den Entscheidungsbaum initialisiert haben, trainieren wir diesen mit den Trainingsdaten.

```{r}
tree_fit_1 <- tree_mod |> 
  fit(Subscription_Status ~ Age + Gender, data = train_data)
```

Nach dem trainieren des Modells können wir uns dieses nun anschauen:

```{r}
tree_fit_1 |> 
  extract_fit_engine() 
```

Hinweis für die Interpretation der Ausgabe:

node) ist die Numerierung des Knoten/Blattes, hierbei wird der nachfolgende Knoten des aktuellen Knotens Nr.x mit 2x und 2x+1 nummeriert. D.h. aus dem Startknoten Nr.1 enstehen die Knoten mit Nr. 2 und 3, auf Nr. 2 folgen die Knoten mit Nr. 4 und 5, auf Nr. 3 die Knoten mit Nr. 6 und 7 usw.

split gibt die letzte Merkmalsbedingung an, die zu diesem Knoten/Blatt geführt hat.

n gibt die Anzahl aller Beobachtungen aus den Trainingsdaten an, die die Merkmalskombinationen, die bis hierhin führen, erfüllen.

loss gibt die falschen Zuordnungen in dem Knoten/Blatt an

yval gibt den Wert der Vorhersagevariablen gemäß des Baums/Modells in diesem Knoten an.

(yprob) gibt die Wahrscheinlichkeiten einer korrekten bzw. einer falschen Zuordnung an, aufgeteilt auf die Klassen und bezogen auf die Vorhersage yval.

'*' bedeutet, dass dieser Knoten ein Endknoten bzw. ein Blatt des Baumes ist und danach kein weiterer Knoten bzw. keine Merkmalsbedingung im Baum mehr erfolgt.

Zu erkennen ist, dass es insgesamt nur 5 Endknoten mit der Vorhersage "Yes" gibt und 10 mit der Vorhersage "No". Die Wahrscheinlichkeit, dass jemand ein Abonnement hat, ist also relativ gering. Insgesamt ca. 2,76% (0.5897436 + 0.5454545 + 0.5348837 + 0.5294118 + 0.5581395). Zudem ist erkennbar, dass die Wahrscheinlichkeit bei Frauen bei 0% liegen. Nun schauen wir uns den Entscheidungsbaum einmal geplottet an:

```{r}
tree_fit_1 |> 
  extract_fit_engine() |> 
  rpart.plot(extra = 102, roundint = FALSE)
```

Hier ist der Entscheidungsbaum etwas schöner dargestellt, jedoch sind die Prozentzahlen mehr gerundet, weswegen für die Vorhersage für ein Abonnement nun bei 5% liegt.

Bestimmen wir nun die Trefferwahrscheinlichkeit:

```{r}
pred <- predict(tree_fit_1, new_data = test_data)
results1 <- test_data |> select(Subscription_Status) |> bind_cols(pred)
accuracy(data = results1, truth = Subscription_Status, estimate = .pred_class)
```

Wir sehen, dass die Trefferwahrscheinlichkeit bei **71.7%** liegt und damit nur ganz okay ist. Insgesamt wurden **28.3%** falsch vorhergesagt.

Erstellen wir nun noch einmal die Confusion-Matrix:

```{r}
conf_mat(data = results1, truth = Subscription_Status, estimate = .pred_class)
```

Die Confusion-Matrix wird nun als Heatmap dargestellt.

```{r}
conf_matrix <- matrix(c(29, 19, 541, 192), nrow = 2, byrow = TRUE,
                      dimnames = list(c("Tatsächlich 1", "Tatsächlich 0"), c("Vorhergesagt 0", "Vorhergesagt 1")))

heatmaply(conf_matrix, 
          colors = c("red", "yellow", "green"), 
          main = "Confusion Matrix")
```

Insgesamt lässt sich daher sagen, dass das Modell eine seher schwache Vorhersage bietet. Die Fehlerquote ist mit 28.3% sehr hoch und insgesamt wurden nur 560 von 781 Vorhersagen richtig getroffen.
:::
:::

# Fazit

In diesem Kapitel wird wird die Arbeit kritisch betrachtet und bewertet. Zudem werden Ideen für weitere Analysen gegeben.

## Bewertung

Zum Schluss dieser Arbeit möchten wir diese nochmals kritisch betrachten. Hierzu gehen wir zunächst auf das verwendete Datenset und im Anschluss auf unsere Arbeitsweisen ein. Dabei hinterfragen wir besonders unser Vorgehen und die erzielten Ergebnisse. Das Datenset ist für die Beantwortung unserer Thesen geeignet. Es umfasst einen Umfang von 3900 Einträgen und ist somit ausreichend repräsentativ. Es gibt jedoch auch einige Kritikpunkte die wir an dieser Stelle anbringen möchten. <br>
<br>
Zunächst die Kritikpunkte am Datenset. Der erste Kritikpunkt ist, dass kein Kaufdatum bei den Datensätzen hinterlegt ist. Dies wäre vorallem gut gewesen, um auch die Jahre, in der die Beobachtungen gemacht wurden, zu vergleichen. <br>
Der zweite Kritikpunkt ist, dass es keine Einträge mit einem Umsatz von über 100$ gibt. Dies ist vor allem für die Vorhersage in den Modellen 3 und  4 von Nachteil, da die Modelle nicht auf einen solchen Fall trainiert werden können.
Ein dritter Kritikpunkt ist, dass es keine Angaben darüber gibt, ob ein Kunde mehrere Produkte gekauft hat. Zu erkennen ist nur, dass ein Kunde eine bestimmte Anzahl an vorherigen Käufen getätigt hat. Hier wäre es noch interessant gewesen, ob ein Kunde in einem Kauf auch mehrere Produkte gekauft hat. Aus dem Datenset ist nicht ersichtlich, dass Kunden mehrfach Käufe getätigt haben könnten. Dies verfälscht wohlmöglich die Vorhersagen der Modelle. Es lässt sich nicht sicher sagen, dass jeder Kauf tatäschlich von einer anderen Person getätigt wurde.  <br>
<br>
Nun zu der kritischen Auseinandersetzung mit unserer Arbeitsweise. Allgemein sind wir strukturiert vorgegangen. Die Thesen wurden ausreichend gründlich analysiert und hinreichend belegt oder wiederlegt. Die Ergebnisse sind nachvollziehbar und die verwendeten Methoden sind angemessen. Hätte das Datenset tiefergreifende Informationen gehabt, hätten die Thesen noch tieferlegend analysiert werden können um so eine bessere Basis für das Erstellen der Modelle zu schaffen. Würden wir diese Arbeit erneut durchführen, würden wir ein anderes Datenset nehmen, welches die Informationen des Kaufdatums, der Umsätze von über 100$ beinhaltet und eine eindeutige Identifizierung des Käufers beinhaltet. So lassen sich die Vorhersagen der Modelle und Vorhersagen besser beurteilen. <br>
Ein weiterer Kritikpunkt ist, dass die Eingrenzung in These 7 von "Norden" und "Süden" der USA nicht genau genug ist. Die Unterteilung der USA in Nord und Süd basiert auf keinen zugrundeliegenden Informationen, sondern wurde "aus dem Gefühl" heraus vorgenommen. Dies kann zu einer Verfälschung der Ergebnisse führen, da die Einteilung nicht objektiv ist und Einträge in "Süd" strenggenommen zu "Nord" gehören könnten und anderes herum. <br>
Ein dritter Kritikpunkt ist die These 3. Hier wird die These zwar widerlegt, jedoch wird nicht der Shipping_Type beachtet. Dies wäre sehr sinnvoll, da es die Versandtypen Express, kostenloser Versand, Next Day Air, Standard, 2-Tage-Versand und Abholung im Geschäft gibt. Hierbei ist es logisch, dass Barzahlung am geringsten ist, da diese nur bei Abholung im Geschäft möglich ist. Daher hätte die These lauten müssen: "Kunden, die den Versandtyp Abholung im Geschäft wählen, zahlen am häufigsten per Barzahlung".

## Ideen für weitere Analysen

Im Folgenden werden Ideen für weitere Analysen aufgeführt, die sich aus dieser Arbeit ergeben haben.

### Analyse und Vorhersage des Review_Rating

Die Spalte Review_Rating könnte noch analysiert werden. Hiermit könnte man analysieren, wie Zufrieden die Kunden im durchschnitt mit dem Kauf sind und ob es einen Zusammenhang zwischen dem Rating und der Anzahl der Käufe gibt. <br>
Zudem könnte versucht werden vorhzusagen, wie glücklich die Käufer mit dem Kauf sind. Die Vorhersage könnte dabei auf Alter und Geschlecht basieren.

### Vorhersage des Shipping Types

Es könnte versucht werden vorherzusagen, welchen Versandtyp ein Kunde wählt. Die Vorhersage könnte dabei auf Alter, Geschlecht und der Anzahl der vorherigen Käufe basieren. Die Vorhersage könnte auch auf den Kaufpreis bezogen sein.

### Genauere Analyse nach Geschlecht und Alter

Eine weitere Idee ist, dass es noch genauere Analysen mit dem Geschlecht und dem Alter gibt. Es könnte geprüft werden, ob es Unterschiedliche Kaufverhalten je nach Alter gibt und ob das Geschlecht einen Einfluss auf das Kaufverhalten hat. <br>
Zudem könnte versucht werden vorherzusagen, ob ein Kunde männlich oder weiblich ist. Die Vorhersage könnte dabei auf Alter und der Anzahl der vorherigen Käufe basieren. Die Vorhersage könnte auch auf den Kaufpreis bezogen sein.

###  Vorhersage der Anzahl der Käufe pro Kategorie

Es könnte versucht werden vorherzusagen, wie viele Käufe ein Kunde in einer bestimmten Kategorie tätigt. Die Vorhersage könnte dabei auf Alter, Geschlecht und der Anzahl der vorherigen Käufe basieren. Die Vorhersage könnte auch auf den Kaufpreis oder auf die Bezahlmethode bezogen sein.

# Quellen

Datenset: <br>
<ul><li><https://www.kaggle.com/datasets/zeesolver/consumer-behavior-and-shopping-habits-dataset/data></li></ul>
US-Map: <br>
<ul><li><https://jtr13.github.io/cc19/different-ways-of-plotting-u-s-map-in-r.html></li>
<li><https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html></li></ul>
Heatmaply: <br>
<ul><li><https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html></li></ul>
Modell 2: <br>
<ul><li><https://www.statology.org/r-glm-predict/#:~:text=predict(object%2C%20newdata%2C%20type,type%20of%20prediction%20to%20make.></li></ul>
Theme: <br>
<ul><li><https://bootswatch.com/minty/></li></ul>

# Bearbeitungs-kennzeichnung

Ole Kepa:
<ul>
<li>2.2 Buttons</li>
<li>4.1 These 1</li>
<li>4.2 These 2</li>
<li>4.3 These 3</li>
<li>5.1 Modell 1</li>
<li>5.2 Modell 2</li>
</ul>

Fabian Elsner:
<ul>
<li>2.1 Beschreibung der Datenquelle</li>
<li>4.4 These 4</li>
<li>4.5 These 5</li>
<li>4.6 These 6</li>
<li>5.3 Modell 3</li>
<li>5.4 Modell 4</li>
<li>5.5 Bewertung Modell 4 und 5</li>
</ul>

Sören Bax:
<ul>
<li>2 Aufgabe und Daten verstehen</li>
<li>2.1 Beschreibung der Datenquelle</li>
<li>2.3 Buttons</li>
<li>3 Untersuchung der Daten</li>
<li>4.7 These 7</li>
<li>4.8 These 8</li>
<li>4.9 These 9</li>
<li>5.6 Modell 5</li>
</ul>

Alle nicht explizit erwähnten Kapitel wurden gemeinsam erarbeitet.

# Ehrenwörtliche Erklärung

Hiermit erklären wir, dass wir die vorliegende Studienarbeit (Produktstudie) selbständig angefertigt haben und die Bearbeiter der einzelnen Abschnitte wahrheitsgemäß angegeben haben. Es wurden nur die in der Arbeit ausdrücklich benannten Quellen und Hilfsmittel benutzt. Wörtlich oder sinngemäß übernommenes Gedankengut haben wir als solches kenntlich gemacht. Diese Arbeit hat in gleicher oder ähnlicher Form ganz oder teilweise noch keiner Prüfungsbehörde vorgelegen.

<!-- Unterschriften in HTML -->
Rietberg, den 23.12.2023 <br>
<img src="./signatures/OleKepa.png" height="50" width="150"/> 
<figcaption>Ole Kepa</figcaption>

Sandebeck, den 23.12.2023 <br>
<img src="./signatures/FabianElsner.png" height="50" width="150"/>
<figcaption>Fabian Elsner</figcaption>

Langenberg, den 23.12.2023 <br>
<img src="./signatures/SoerenBax.png" height="50" width="150"/>
<figcaption>Sören Bax</figcaption>